{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96512697",
   "metadata": {
    "papermill": {
     "duration": 0.001702,
     "end_time": "2026-02-24T00:55:49.229003",
     "exception": false,
     "start_time": "2026-02-24T00:55:49.227301",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "title: Using ConvNets with Small Datasets\n",
    "---\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pantelis/aiml-common/blob/master/lectures/cnn/cnn-example-architectures/using_convnets_with_small_datasets.ipynb)\n",
    "\n",
    "This notebook is a PyTorch adaptation of the canonical small-dataset convnet example from\n",
    "[Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python) (F. Chollet, Chapter 5).\n",
    "\n",
    "We use the `pantelism/cats-vs-dogs` dataset hosted on Hugging Face (the same 4,000-image Kaggle\n",
    "subset used in the original) and demonstrate:\n",
    "\n",
    "1. **Baseline**: training a small convnet from scratch → clear overfitting with only 2,000 training samples\n",
    "2. **Regularisation**: data augmentation + dropout → substantially lower validation loss and higher accuracy\n",
    "\n",
    "The trained model is saved as `cats_and_dogs_small.pth` for use by the companion\n",
    "visualisation notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6e5b9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-24T00:55:49.233043Z",
     "iopub.status.busy": "2026-02-24T00:55:49.232872Z",
     "iopub.status.idle": "2026-02-24T00:55:49.363400Z",
     "shell.execute_reply": "2026-02-24T00:55:49.361240Z"
    },
    "papermill": {
     "duration": 0.135266,
     "end_time": "2026-02-24T00:55:49.365933",
     "exception": false,
     "start_time": "2026-02-24T00:55:49.230667",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": "!pip install datasets scikit-learn seaborn --quiet\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f8845b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-24T00:55:49.376789Z",
     "iopub.status.busy": "2026-02-24T00:55:49.376355Z",
     "iopub.status.idle": "2026-02-24T00:55:52.267430Z",
     "shell.execute_reply": "2026-02-24T00:55:52.266773Z"
    },
    "papermill": {
     "duration": 2.897746,
     "end_time": "2026-02-24T00:55:52.268195",
     "exception": false,
     "start_time": "2026-02-24T00:55:49.370449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import confusion_matrix, roc_curve\n",
    "import seaborn as sns\n",
    "\n",
    "# ── Config ──────────────────────────────────────────────────────────────────\n",
    "IMG_SIZE        = 150\n",
    "BATCH_SIZE      = 32\n",
    "EPOCHS_BASELINE = 20   # enough to show overfitting clearly\n",
    "EPOCHS_AUG      = 30   # enough to show regularisation benefit\n",
    "LR              = 1e-4\n",
    "SEED            = 42\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {DEVICE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c4d3d0",
   "metadata": {
    "papermill": {
     "duration": 0.001443,
     "end_time": "2026-02-24T00:55:52.271334",
     "exception": false,
     "start_time": "2026-02-24T00:55:52.269891",
     "status": "completed"
    },
    "tags": []
   },
   "source": "## Dataset\n\n`pantelism/cats-vs-dogs` is a Parquet imagefolder dataset on Hugging Face containing\nthe 4,000-image Kaggle cats-vs-dogs subset used in the original Chollet notebook.\nIt has three pre-built splits — `train` (2,000 images), `validation` (1,000), and\n`test` (1,000) — with a `ClassLabel` feature mapping 0 → `cat` and 1 → `dog`.\n\nWe load it directly with `load_dataset` and wrap it in a lightweight PyTorch `Dataset`.\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a5c139",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-24T00:55:52.275194Z",
     "iopub.status.busy": "2026-02-24T00:55:52.274885Z",
     "iopub.status.idle": "2026-02-24T00:55:55.153723Z",
     "shell.execute_reply": "2026-02-24T00:55:55.153132Z"
    },
    "papermill": {
     "duration": 2.881623,
     "end_time": "2026-02-24T00:55:55.154332",
     "exception": false,
     "start_time": "2026-02-24T00:55:52.272709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": "from datasets import load_dataset\nfrom torch.utils.data import Dataset\n\n# ── Load dataset ──────────────────────────────────────────────────────────────\n# pantelism/cats-vs-dogs is a Parquet imagefolder dataset with three splits\nds_dict = load_dataset(\"pantelism/cats-vs-dogs\")\n\nlabel_names = ds_dict[\"train\"].features[\"label\"].names  # ['cat', 'dog']\nprint(f\"Train {len(ds_dict['train'])} | Val {len(ds_dict['validation'])} | Test {len(ds_dict['test'])}\")\nprint(\"Labels:\", label_names)\n\n# ── PyTorch Dataset wrapper ───────────────────────────────────────────────────\nclass CatsDogsDataset(Dataset):\n    def __init__(self, hf_dataset, transform):\n        self.data      = hf_dataset\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        sample = self.data[idx]\n        img    = sample[\"image\"].convert(\"RGB\")\n        label  = float(sample[\"label\"])   # ClassLabel int → float for BCEWithLogitsLoss\n        return self.transform(img), label\n\n# ── Transforms ───────────────────────────────────────────────────────────────\nbasic_tf = transforms.Compose([\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n])\n\naug_tf = transforms.Compose([\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(40),\n    transforms.RandomAffine(degrees=0, translate=(0.2, 0.2), shear=20),\n    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0)),\n    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n])\n\n# ── DataLoaders ──────────────────────────────────────────────────────────────\ndef make_loader(hf_split, tf, shuffle=False):\n    return DataLoader(\n        CatsDogsDataset(hf_split, tf),\n        batch_size=BATCH_SIZE,\n        shuffle=shuffle,\n        num_workers=2,\n        pin_memory=True,\n    )\n\ntrain_loader_basic = make_loader(ds_dict[\"train\"],      basic_tf, shuffle=True)\ntrain_loader_aug   = make_loader(ds_dict[\"train\"],      aug_tf,   shuffle=True)\nval_loader         = make_loader(ds_dict[\"validation\"], basic_tf)\ntest_loader        = make_loader(ds_dict[\"test\"],       basic_tf)\n\nimgs, labels = next(iter(train_loader_basic))\nprint(f\"Batch shape: {imgs.shape}, Labels: {labels[:8].tolist()}\")\n"
  },
  {
   "cell_type": "markdown",
   "id": "252f316a",
   "metadata": {
    "papermill": {
     "duration": 0.001625,
     "end_time": "2026-02-24T00:55:55.157871",
     "exception": false,
     "start_time": "2026-02-24T00:55:55.156246",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model architecture\n",
    "\n",
    "We replicate the Chollet convnet — four `Conv2d → ReLU → MaxPool2d` blocks that\n",
    "progressively increase depth (32 → 64 → 128 → 128) while halving spatial dimensions\n",
    "(150 → 74 → 36 → 17 → 7), followed by a fully-connected head.\n",
    "\n",
    "An optional `Dropout(0.5)` layer is inserted before the first dense layer for the\n",
    "regularised variant.\n",
    "\n",
    "```\n",
    "Input 3×150×150\n",
    "  Conv2d(3→32, k=3)  → ReLU → MaxPool2d(2)   →  32×74×74\n",
    "  Conv2d(32→64, k=3) → ReLU → MaxPool2d(2)   →  64×36×36\n",
    "  Conv2d(64→128,k=3) → ReLU → MaxPool2d(2)   → 128×17×17\n",
    "  Conv2d(128→128,k=3)→ ReLU → MaxPool2d(2)   → 128×7×7\n",
    "  Flatten → [Dropout(0.5)] → Linear(6272→512) → ReLU → Linear(512→1)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562dc167",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-24T00:55:55.162420Z",
     "iopub.status.busy": "2026-02-24T00:55:55.162239Z",
     "iopub.status.idle": "2026-02-24T00:55:55.220612Z",
     "shell.execute_reply": "2026-02-24T00:55:55.220184Z"
    },
    "papermill": {
     "duration": 0.062028,
     "end_time": "2026-02-24T00:55:55.221440",
     "exception": false,
     "start_time": "2026-02-24T00:55:55.159412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SmallConvNet(nn.Module):\n",
    "    def __init__(self, dropout: bool = False):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3,   32,  3), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32,  64,  3), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64,  128, 3), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(128, 128, 3), nn.ReLU(), nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5) if dropout else nn.Identity(),\n",
    "            nn.Linear(128 * 7 * 7, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.classifier(x).squeeze(1)   # shape (B,)\n",
    "\n",
    "# Verify output shape\n",
    "_dummy = torch.zeros(2, 3, IMG_SIZE, IMG_SIZE)\n",
    "assert SmallConvNet()(_dummy).shape == (2,), \"unexpected output shape\"\n",
    "print(\"Architecture verified — output shape (B,) ✓\")\n",
    "print(SmallConvNet())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e479696a",
   "metadata": {
    "papermill": {
     "duration": 0.001731,
     "end_time": "2026-02-24T00:55:55.224934",
     "exception": false,
     "start_time": "2026-02-24T00:55:55.223203",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Baseline: training from scratch with no regularisation\n",
    "\n",
    "We train for 20 epochs with RMSprop and binary cross-entropy loss.\n",
    "With only 2,000 training samples the network overfits quickly:\n",
    "training accuracy climbs to ~95% while validation accuracy plateaus\n",
    "around 70–72%, a textbook overfitting signature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e821a09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-24T00:55:55.228851Z",
     "iopub.status.busy": "2026-02-24T00:55:55.228696Z",
     "iopub.status.idle": "2026-02-24T00:56:56.681305Z",
     "shell.execute_reply": "2026-02-24T00:56:56.680380Z"
    },
    "papermill": {
     "duration": 61.455606,
     "end_time": "2026-02-24T00:56:56.682032",
     "exception": false,
     "start_time": "2026-02-24T00:55:55.226426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, epochs, lr=LR):\n",
    "    model = model.to(DEVICE)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimiser = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "\n",
    "    history = dict(train_loss=[], val_loss=[], train_acc=[], val_acc=[])\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # ── Training pass ────────────────────────────────────────────────────\n",
    "        model.train()\n",
    "        t_loss = t_correct = t_n = 0\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs   = imgs.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)   # already float from CatsDogsDataset\n",
    "            optimiser.zero_grad()\n",
    "            logits = model(imgs)\n",
    "            loss   = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "            t_loss    += loss.item() * len(imgs)\n",
    "            t_correct += ((logits > 0) == labels.bool()).sum().item()\n",
    "            t_n       += len(imgs)\n",
    "\n",
    "        # ── Validation pass ──────────────────────────────────────────────────\n",
    "        model.eval()\n",
    "        v_loss = v_correct = v_n = 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in val_loader:\n",
    "                imgs   = imgs.to(DEVICE)\n",
    "                labels = labels.float().to(DEVICE)\n",
    "                logits = model(imgs)\n",
    "                v_loss    += criterion(logits, labels).item() * len(imgs)\n",
    "                v_correct += ((logits > 0) == labels.bool()).sum().item()\n",
    "                v_n       += len(imgs)\n",
    "\n",
    "        history[\"train_loss\"].append(t_loss / t_n)\n",
    "        history[\"train_acc\"].append(t_correct / t_n)\n",
    "        history[\"val_loss\"].append(v_loss / v_n)\n",
    "        history[\"val_acc\"].append(v_correct / v_n)\n",
    "\n",
    "        if (epoch + 1) % 5 == 0 or epoch == 0:\n",
    "            print(\n",
    "                f\"Epoch {epoch+1:3d}/{epochs}  \"\n",
    "                f\"loss {history['train_loss'][-1]:.4f}  acc {history['train_acc'][-1]:.3f}  |  \"\n",
    "                f\"val_loss {history['val_loss'][-1]:.4f}  val_acc {history['val_acc'][-1]:.3f}\"\n",
    "            )\n",
    "    return history\n",
    "\n",
    "\n",
    "def plot_history(history, title, save_path=None):\n",
    "    epochs = range(1, len(history[\"train_acc\"]) + 1)\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    ax1.plot(epochs, history[\"train_acc\"], \"bo-\", label=\"Training\")\n",
    "    ax1.plot(epochs, history[\"val_acc\"],   \"b-\",  label=\"Validation\")\n",
    "    ax1.set_title(f\"{title} — Accuracy\"); ax1.set_xlabel(\"Epoch\"); ax1.legend()\n",
    "    ax2.plot(epochs, history[\"train_loss\"], \"ro-\", label=\"Training\")\n",
    "    ax2.plot(epochs, history[\"val_loss\"],   \"r-\",  label=\"Validation\")\n",
    "    ax2.set_title(f\"{title} — Loss\"); ax2.set_xlabel(\"Epoch\"); ax2.legend()\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=120, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "model_baseline = SmallConvNet(dropout=False)\n",
    "print(\"Training baseline …\")\n",
    "hist_baseline = train_model(model_baseline, train_loader_basic, val_loader, EPOCHS_BASELINE)\n",
    "plot_history(hist_baseline, \"Baseline (no augmentation)\", \"baseline_curves.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20123ee0",
   "metadata": {
    "papermill": {
     "duration": 0.0028,
     "end_time": "2026-02-24T00:56:56.688000",
     "exception": false,
     "start_time": "2026-02-24T00:56:56.685200",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data augmentation + dropout\n",
    "\n",
    "Data augmentation generates new views of each training image on-the-fly — random\n",
    "horizontal flips, rotations, translations, shears, and crop-resizes — so the model\n",
    "never sees the exact same pixel pattern twice.  Combined with `Dropout(0.5)`, this\n",
    "substantially reduces the train-validation gap characteristic of overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc0eec8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-24T00:56:56.695411Z",
     "iopub.status.busy": "2026-02-24T00:56:56.695201Z",
     "iopub.status.idle": "2026-02-24T00:59:23.081415Z",
     "shell.execute_reply": "2026-02-24T00:59:23.080732Z"
    },
    "papermill": {
     "duration": 146.391319,
     "end_time": "2026-02-24T00:59:23.082091",
     "exception": false,
     "start_time": "2026-02-24T00:56:56.690772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)\n",
    "model_aug = SmallConvNet(dropout=True)\n",
    "print(\"Training augmented model (data augmentation + dropout) …\")\n",
    "hist_aug = train_model(model_aug, train_loader_aug, val_loader, EPOCHS_AUG)\n",
    "plot_history(hist_aug, \"Augmentation + Dropout\", \"augmented_curves.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d238333c",
   "metadata": {
    "papermill": {
     "duration": 0.00406,
     "end_time": "2026-02-24T00:59:23.090635",
     "exception": false,
     "start_time": "2026-02-24T00:59:23.086575",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Evaluation on the held-out test set\n",
    "\n",
    "We evaluate the regularised model on the 1,000-image test split and report:\n",
    "\n",
    "- **Confusion matrix** — to see which mistakes are made\n",
    "- **ROC curve** — to characterise the trade-off across thresholds\n",
    "- **Test accuracy** — headline metric\n",
    "\n",
    "The model is saved as `cats_and_dogs_small.pth` for the companion\n",
    "visualisation notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5c0587",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-24T00:59:23.100145Z",
     "iopub.status.busy": "2026-02-24T00:59:23.099919Z",
     "iopub.status.idle": "2026-02-24T00:59:24.616261Z",
     "shell.execute_reply": "2026-02-24T00:59:24.615712Z"
    },
    "papermill": {
     "duration": 1.522525,
     "end_time": "2026-02-24T00:59:24.617064",
     "exception": false,
     "start_time": "2026-02-24T00:59:23.094539",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ── Save model ───────────────────────────────────────────────────────────────\n",
    "torch.save(model_aug.state_dict(), \"cats_and_dogs_small.pth\")\n",
    "print(\"Saved cats_and_dogs_small.pth\")\n",
    "\n",
    "# ── Collect predictions ──────────────────────────────────────────────────────\n",
    "model_aug.eval()\n",
    "all_labels, all_probs = [], []\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in test_loader:\n",
    "        logits = model_aug(imgs.to(DEVICE))\n",
    "        probs  = torch.sigmoid(logits).cpu().numpy()\n",
    "        all_probs.extend(probs)\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "all_labels = np.array(all_labels, dtype=int)\n",
    "all_probs  = np.array(all_probs)\n",
    "preds      = (all_probs > 0.5).astype(int)\n",
    "\n",
    "# ── Confusion matrix + ROC ───────────────────────────────────────────────────\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "cm = confusion_matrix(all_labels, preds)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", ax=axes[0], cmap=\"Blues\",\n",
    "            xticklabels=label_names, yticklabels=label_names)\n",
    "axes[0].set_title(\"Confusion matrix (test set)\")\n",
    "axes[0].set_ylabel(\"True label\"); axes[0].set_xlabel(\"Predicted label\")\n",
    "\n",
    "fp, tp, _ = roc_curve(all_labels, all_probs)\n",
    "axes[1].plot(100 * fp, 100 * tp, linewidth=2)\n",
    "axes[1].set_xlabel(\"False positive rate [%]\"); axes[1].set_ylabel(\"True positive rate [%]\")\n",
    "axes[1].set_title(\"ROC curve\"); axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"evaluation.png\", dpi=120, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "acc = (preds == all_labels).mean()\n",
    "print(f\"Test accuracy: {acc:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 217.30931,
   "end_time": "2026-02-24T00:59:25.841823",
   "environment_variables": {},
   "exception": null,
   "input_path": "notebooks/cnn/using_convnets_with_small_datasets.ipynb",
   "output_path": "notebooks/cnn/using_convnets_with_small_datasets-executed.ipynb",
   "parameters": {},
   "start_time": "2026-02-24T00:55:48.532513",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
