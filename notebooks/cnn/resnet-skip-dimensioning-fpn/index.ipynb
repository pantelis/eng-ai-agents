{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd84451d",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [2]</a>'.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7144ea7",
   "metadata": {
    "papermill": {
     "duration": 0.006881,
     "end_time": "2026-02-26T21:29:36.759936",
     "exception": false,
     "start_time": "2026-02-26T21:29:36.753055",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "title: ResNet Skip-Connection Dimensioning and FPN\n",
    "description: how 1×1 projection skip connections handle dimension mismatches, and the canonical FPN featurizer that unifies backbone channels to d=256.\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d906a5b6",
   "metadata": {
    "papermill": {
     "duration": 0.003709,
     "end_time": "2026-02-26T21:29:36.770187",
     "exception": false,
     "start_time": "2026-02-26T21:29:36.766478",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## The core dimensional constraint\n",
    "\n",
    "Let $x \\in \\mathbb{R}^{B \\times C_{in} \\times H \\times W}$. A residual unit computes\n",
    "\n",
    "\n",
    "$$y = F(x) + \\mathcal{S}(x)$$\n",
    "\n",
    "\n",
    "and **addition requires identical tensor shapes**:\n",
    "\n",
    "$$\n",
    "F(x), \\mathcal{S}(x) \\in \\mathbb{R}^{B \\times C_{out} \\times H' \\times W'}.\n",
    "$$\n",
    "\n",
    "Hence the skip connection must handle two mismatches:\n",
    "- channel mismatch: $C_{in} \\neq C_{out}$\n",
    "- spatial mismatch: $(H,W) \\neq (H',W')$ (typically caused by stride-2 downsampling)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aea7c6f",
   "metadata": {
    "papermill": {
     "duration": 0.001636,
     "end_time": "2026-02-26T21:29:36.774211",
     "exception": false,
     "start_time": "2026-02-26T21:29:36.772575",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Residual block — skip connection options\n",
    "\n",
    "```mermaid\n",
    "flowchart LR\n",
    "    x[\"x\\n[B, Cᵢₙ, H, W]\"]\n",
    "    x --> c1[\"Conv 3×3\\nstride s\"]\n",
    "    c1 --> b1[\"BN + ReLU\"]\n",
    "    b1 --> c2[\"Conv 3×3\\nstride 1\"]\n",
    "    c2 --> b2[\"BN\"]\n",
    "    b2 --> add[\"⊕ Add\"]\n",
    "    x -->|\"Cᵢₙ=Cₒᵤₜ, s=1\"| id[\"Identity\"]\n",
    "    x -->|\"else\"| proj[\"1×1 Conv, stride s\\nOption B\"]\n",
    "    id --> add\n",
    "    proj --> add\n",
    "    add --> relu[\"ReLU\"]\n",
    "    relu --> y[\"y\\n[B, Cₒᵤₜ, H/s, W/s]\"]\n",
    "```\n",
    "\n",
    "Addition **requires identical tensor shapes**: both the residual branch and the skip connection must produce $[B, C_{out}, H', W']$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa35642",
   "metadata": {
    "papermill": {
     "duration": 0.001323,
     "end_time": "2026-02-26T21:29:36.776924",
     "exception": false,
     "start_time": "2026-02-26T21:29:36.775601",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## ResNet-style block with correct skip connection dimensioning\n",
    "\n",
    "We implement a standard BasicBlock with:\n",
    "- residual branch: 3×3 conv → BN → ReLU → 3×3 conv → BN\n",
    "- skip connection:\n",
    "  - identity if stride=1 and $C_{in}=C_{out}$\n",
    "  - otherwise a 1×1 conv (projection), with the same stride as the residual branch’s downsampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b33991e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-26T21:29:36.781244Z",
     "iopub.status.busy": "2026-02-26T21:29:36.781092Z",
     "iopub.status.idle": "2026-02-26T21:29:37.743038Z",
     "shell.execute_reply": "2026-02-26T21:29:37.742469Z"
    },
    "papermill": {
     "duration": 0.965528,
     "end_time": "2026-02-26T21:29:37.743797",
     "exception": false,
     "start_time": "2026-02-26T21:29:36.778269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, cin: int, cout: int, stride: int = 1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(cin, cout, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1   = nn.BatchNorm2d(cout)\n",
    "        self.conv2 = nn.Conv2d(cout, cout, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2   = nn.BatchNorm2d(cout)\n",
    "        self.relu  = nn.ReLU(inplace=True)\n",
    "\n",
    "        if stride != 1 or cin != cout:\n",
    "            # Projection skip connection: matches channels and spatial size.\n",
    "            self.skip_connection = nn.Sequential(\n",
    "                nn.Conv2d(cin, cout, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(cout),\n",
    "            )\n",
    "        else:\n",
    "            self.skip_connection = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out = out + self.skip_connection(x)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "def report(name: str, t) -> None:\n",
    "    \"\"\"Print tensor name, shape, dtype, and device.\"\"\"\n",
    "    print(f\"{name}: shape={tuple(t.shape)}  dtype={t.dtype}  device={t.device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ad3d3c",
   "metadata": {
    "papermill": {
     "duration": 0.001679,
     "end_time": "2026-02-26T21:29:37.747435",
     "exception": false,
     "start_time": "2026-02-26T21:29:37.745756",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Option A vs. Option B (ResNet paper terminology)\n",
    "\n",
    "In the ResNet paper’s discussion:\n",
    "\n",
    "- Option A: downsample the skip connection (stride 2) and **zero-pad channels** to match $C_{out}$.\n",
    "\n",
    "- Option B: downsample and **project with 1×1 conv** to match dimensions.\n",
    "\n",
    "For FPN-style backbones, **Option B is the preferred practical choice** because:\n",
    "- the feature hierarchy is consumed downstream (e.g., lateral merges), so having a learned projection at stage transitions is robust,\n",
    "- and it matches the canonical ResNet-{50,101,152} “option B” design in the CVPR paper.\n",
    "\n",
    "Below is a small functional illustration of “Option A-like” padding for the channel mismatch (spatial downsample uses strided slicing for simplicity).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97fd0c8",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7372f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-26T21:29:37.751565Z",
     "iopub.status.busy": "2026-02-26T21:29:37.751338Z",
     "iopub.status.idle": "2026-02-26T21:29:37.890253Z",
     "shell.execute_reply": "2026-02-26T21:29:37.889440Z"
    },
    "papermill": {
     "duration": 0.142275,
     "end_time": "2026-02-26T21:29:37.891176",
     "exception": true,
     "start_time": "2026-02-26T21:29:37.748901",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def option_a_skip_connection(x, cout: int, stride: int):\n",
    "    # Spatial downsample: emulate stride-2 skip connection by subsampling.\n",
    "    if stride == 2:\n",
    "        x_ds = x[:, :, ::2, ::2]\n",
    "    elif stride == 1:\n",
    "        x_ds = x\n",
    "    else:\n",
    "        raise ValueError(\"This demo only supports stride 1 or 2.\")\n",
    "    cin = x_ds.shape[1]\n",
    "    if cin > cout:\n",
    "        raise ValueError(\"Option A padding demo expects cin <= cout.\")\n",
    "    if cin == cout:\n",
    "        return x_ds\n",
    "    pad_c = cout - cin\n",
    "    # Pad channels: (N,C,H,W). We pad on the channel dimension by concatenating zeros.\n",
    "    zeros = torch.zeros(x_ds.shape[0], pad_c, x_ds.shape[2], x_ds.shape[3], device=x_ds.device, dtype=x_ds.dtype)\n",
    "    return torch.cat([x_ds, zeros], dim=1)\n",
    "\n",
    "# Demonstrate option A-like skip connection shape matching\n",
    "x = torch.randn(2, 64, 56, 56)\n",
    "Sx_a = option_a_skip_connection(x, cout=128, stride=2)\n",
    "report(\"Option-A-like S(x)\", Sx_a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e95cd74",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## A minimal ResNet-like backbone that exposes {C2, C3, C4, C5}\n",
    "\n",
    "FPN (Lin et al.) uses the outputs of each ResNet stage’s last block:\n",
    "\\{C2, C3, C4, C5\\} with strides \\{4, 8, 16, 32\\} relative to the input.\n",
    "\n",
    "We build a small backbone that mirrors this structure (conceptually like a tiny ResNet-18).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d894e061",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Backbone stage layout — strides and channel widths\n",
    "\n",
    "```mermaid\n",
    "flowchart LR\n",
    "    img[\"Image\\n3×224×224\"]\n",
    "    stem[\"Stem\\nConv7 s2 + MaxPool s2\\n64×56×56\"]\n",
    "    c2[\"Stage 1\\n64×56×56\\n→ C2 stride 4\"]\n",
    "    c3[\"Stage 2\\n128×28×28\\n→ C3 stride 8\"]\n",
    "    c4[\"Stage 3\\n256×14×14\\n→ C4 stride 16\"]\n",
    "    c5[\"Stage 4\\n512×7×7\\n→ C5 stride 32\"]\n",
    "    img --> stem --> c2 -->|\"stride 2\"| c3 -->|\"stride 2\"| c4 -->|\"stride 2\"| c5\n",
    "```\n",
    "\n",
    "Each stage transition uses a stride-2 first block with a **1×1 projection skip connection** (Option B) to match dimensions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85066b3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T16:59:59.557803Z",
     "iopub.status.busy": "2026-02-25T16:59:59.557648Z",
     "iopub.status.idle": "2026-02-25T16:59:59.630380Z",
     "shell.execute_reply": "2026-02-25T16:59:59.629884Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TinyResNetBackbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Stem (like ResNet): stride-2 conv + stride-2 maxpool => output stride 4\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "        )\n",
    "        # Stages: produce C2..C5\n",
    "        self.layer1 = nn.Sequential(BasicBlock(64,  64, stride=1), BasicBlock(64,  64, stride=1))  # C2, stride 4\n",
    "        self.layer2 = nn.Sequential(BasicBlock(64, 128, stride=2), BasicBlock(128, 128, stride=1)) # C3, stride 8\n",
    "        self.layer3 = nn.Sequential(BasicBlock(128,256, stride=2), BasicBlock(256, 256, stride=1)) # C4, stride 16\n",
    "        self.layer4 = nn.Sequential(BasicBlock(256,512, stride=2), BasicBlock(512, 512, stride=1)) # C5, stride 32\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        c2 = self.layer1(x)\n",
    "        c3 = self.layer2(c2)\n",
    "        c4 = self.layer3(c3)\n",
    "        c5 = self.layer4(c4)\n",
    "        return {\"C2\": c2, \"C3\": c3, \"C4\": c4, \"C5\": c5}\n",
    "\n",
    "backbone = TinyResNetBackbone()\n",
    "x = torch.randn(1, 3, 224, 224)\n",
    "C = backbone(x)\n",
    "for k in [\"C2\",\"C3\",\"C4\",\"C5\"]:\n",
    "    report(k, C[k])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69904b6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T16:59:59.636268Z",
     "iopub.status.busy": "2026-02-25T16:59:59.636118Z",
     "iopub.status.idle": "2026-02-25T17:00:00.326441Z",
     "shell.execute_reply": "2026-02-25T17:00:00.325865Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "stages = ['C2\\n(stride 4)', 'C3\\n(stride 8)', 'C4\\n(stride 16)', 'C5\\n(stride 32)']\n",
    "channels_bb = [64, 128, 256, 512]\n",
    "spatial_bb  = [56, 28, 14, 7]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(11, 4))\n",
    "colors = ['#4e79a7', '#f28e2b', '#e15759', '#76b7b2']\n",
    "\n",
    "bars1 = ax1.bar(stages, channels_bb, color=colors)\n",
    "ax1.set_ylabel('Channels')\n",
    "ax1.set_title('Channel width per backbone stage')\n",
    "for b, v in zip(bars1, channels_bb):\n",
    "    ax1.text(b.get_x() + b.get_width()/2, b.get_height() + 4, str(v),\n",
    "             ha='center', fontweight='bold')\n",
    "\n",
    "bars2 = ax2.bar(stages, spatial_bb, color=colors)\n",
    "ax2.set_ylabel('Spatial size (H = W, pixels)')\n",
    "ax2.set_title('Feature map spatial size per backbone stage\\n(input 224×224)')\n",
    "for b, v in zip(bars2, spatial_bb):\n",
    "    ax2.text(b.get_x() + b.get_width()/2, b.get_height() + 0.4, f'{v}×{v}',\n",
    "             ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('backbone_dimensions.png', dpi=120, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ebedaa",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## FPN module implementation\n",
    "\n",
    "Canonical FPN design choices (as in Lin et al.):\n",
    "- 1×1 lateral conv to unify channels to $d=256$\n",
    "- top-down upsample by factor 2 (nearest neighbor is typical)\n",
    "- element-wise addition (requires same $H \\times W$ and same $d$)\n",
    "- 3×3 conv “smoothing” on each merged map\n",
    "- optional $P6$ via stride-2 3×3 conv on $P5$ (common in detection systems)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b43c2e2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### FPN top-down pathway — lateral merges and channel unification\n",
    "\n",
    "```mermaid\n",
    "flowchart TB\n",
    "    C5[\"C5: 512×7×7\"] -->|\"Lat 1×1\"| M5[\"M5: 256×7×7\"]\n",
    "    C4[\"C4: 256×14×14\"] -->|\"Lat 1×1\"| lat4[\"256×14×14\"]\n",
    "    C3[\"C3: 128×28×28\"] -->|\"Lat 1×1\"| lat3[\"256×28×28\"]\n",
    "    C2[\"C2: 64×56×56\"] -->|\"Lat 1×1\"| lat2[\"256×56×56\"]\n",
    "    M5 -->|\"Up ×2\"| up5[\"256×14×14\"]\n",
    "    up5 -->|\"⊕\"| M4[\"M4: 256×14×14\"]\n",
    "    lat4 --> M4\n",
    "    M4 -->|\"Up ×2\"| up4[\"256×28×28\"]\n",
    "    up4 -->|\"⊕\"| M3[\"M3: 256×28×28\"]\n",
    "    lat3 --> M3\n",
    "    M3 -->|\"Up ×2\"| up3[\"256×56×56\"]\n",
    "    up3 -->|\"⊕\"| M2[\"M2: 256×56×56\"]\n",
    "    lat2 --> M2\n",
    "    M5 -->|\"3×3 Conv\"| P5[\"P5\"]\n",
    "    M4 -->|\"3×3 Conv\"| P4[\"P4\"]\n",
    "    M3 -->|\"3×3 Conv\"| P3[\"P3\"]\n",
    "    M2 -->|\"3×3 Conv\"| P2[\"P2\"]\n",
    "    P5 -->|\"3×3 s2\"| P6[\"P6\"]\n",
    "```\n",
    "\n",
    "The 1×1 lateral convolutions unify **heterogeneous backbone channels** (64/128/256/512) to a **uniform $d=256$** before the element-wise additions. The additions require strict spatial and channel alignment — which the lateral convolutions and upsample guarantee.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce736458",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-25T17:00:00.343072Z",
     "iopub.status.busy": "2026-02-25T17:00:00.342859Z",
     "iopub.status.idle": "2026-02-25T17:00:00.393692Z",
     "shell.execute_reply": "2026-02-25T17:00:00.393052Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FPN(nn.Module):\n",
    "    def __init__(self, c2: int, c3: int, c4: int, c5: int, d: int = 256, make_p6: bool = True):\n",
    "        super().__init__()\n",
    "        # Lateral 1×1 convs: Ck -> d\n",
    "        self.lat2 = nn.Conv2d(c2, d, kernel_size=1)\n",
    "        self.lat3 = nn.Conv2d(c3, d, kernel_size=1)\n",
    "        self.lat4 = nn.Conv2d(c4, d, kernel_size=1)\n",
    "        self.lat5 = nn.Conv2d(c5, d, kernel_size=1)\n",
    "\n",
    "        # Smoothing 3×3 convs on each pyramid level\n",
    "        self.smooth2 = nn.Conv2d(d, d, kernel_size=3, padding=1)\n",
    "        self.smooth3 = nn.Conv2d(d, d, kernel_size=3, padding=1)\n",
    "        self.smooth4 = nn.Conv2d(d, d, kernel_size=3, padding=1)\n",
    "        self.smooth5 = nn.Conv2d(d, d, kernel_size=3, padding=1)\n",
    "\n",
    "        self.make_p6 = make_p6\n",
    "        self.p6 = nn.Conv2d(d, d, kernel_size=3, stride=2, padding=1) if make_p6 else None\n",
    "\n",
    "    def forward(self, C):\n",
    "        c2, c3, c4, c5 = C[\"C2\"], C[\"C3\"], C[\"C4\"], C[\"C5\"]\n",
    "\n",
    "        m5 = self.lat5(c5)\n",
    "        m4 = self.lat4(c4) + F.interpolate(m5, scale_factor=2.0, mode=\"nearest\")\n",
    "        m3 = self.lat3(c3) + F.interpolate(m4, scale_factor=2.0, mode=\"nearest\")\n",
    "        m2 = self.lat2(c2) + F.interpolate(m3, scale_factor=2.0, mode=\"nearest\")\n",
    "\n",
    "        p5 = self.smooth5(m5)\n",
    "        p4 = self.smooth4(m4)\n",
    "        p3 = self.smooth3(m3)\n",
    "        p2 = self.smooth2(m2)\n",
    "\n",
    "        out = {\"P2\": p2, \"P3\": p3, \"P4\": p4, \"P5\": p5}\n",
    "        if self.make_p6:\n",
    "            out[\"P6\"] = self.p6(p5)\n",
    "        return out\n",
    "\n",
    "fpn = FPN(c2=64, c3=128, c4=256, c5=512, d=256, make_p6=True)\n",
    "\n",
    "P = fpn(C)\n",
    "for k in [\"P2\",\"P3\",\"P4\",\"P5\",\"P6\"]:\n",
    "    report(k, P[k])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1a343a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## What “preferred approach for FPN” means (operationally)\n",
    "\n",
    "In a modern featurizer intended for FPN-style consumption, the pragmatic default is:\n",
    "\n",
    "1. Backbone (ResNet-style):\n",
    "   - Identity skip connection if $(C_{in}, H, W)$ matches $(C_{out}, H', W')$\n",
    "   - 1×1 projection skip connection (with stride=2 when downsampling) otherwise  \n",
    "   This matches the ResNet paper’s “projection to match dimensions” guidance and the widespread “option B” practice in deep variants.\n",
    "\n",
    "2. FPN neck:\n",
    "   - 1×1 lateral convs to unify all $C2..C5$ to $d=256$ channels\n",
    "   - top-down nearest-neighbor upsample by 2\n",
    "   - elementwise addition\n",
    "   - 3×3 smoothing conv\n",
    "   - optional $P6$ from $P5$ via stride-2 3×3 conv\n",
    "\n",
    "The key theme is the same in both ResNet and FPN: **addition enforces strict shape equality**, so dimensioning is not a detail—it is the design constraint.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df806e04",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## References (primary sources)\n",
    "\n",
    "- Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun. *Deep Residual Learning for Image Recognition*. CVPR 2016. arXiv:1512.03385.\n",
    "- Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun. *Identity Mappings in Deep Residual Networks*. ECCV 2016. arXiv:1603.05027.\n",
    "- Tsung-Yi Lin, Piotr Dollár, Ross Girshick, Kaiming He, Bharath Hariharan, Serge Belongie. *Feature Pyramid Networks for Object Detection*. CVPR 2017. arXiv:1612.03144.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5.204181,
   "end_time": "2026-02-26T21:29:41.236780",
   "environment_variables": {},
   "exception": true,
   "input_path": "notebooks/cnn/resnet-skip-dimensioning-fpn/index.ipynb",
   "output_path": "notebooks/cnn/resnet-skip-dimensioning-fpn/index-executed.ipynb",
   "parameters": {},
   "start_time": "2026-02-26T21:29:36.032599",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
