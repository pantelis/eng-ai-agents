{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b50c8dc2",
   "metadata": {
    "papermill": {
     "duration": 0.005565,
     "end_time": "2026-02-12T20:15:32.837790",
     "exception": false,
     "start_time": "2026-02-12T20:15:32.832225",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "title: SGD Example for Linear Regression\n",
    "format:\n",
    "    html: default\n",
    "    ipynb: default\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Colab Environment Setup ---\n",
    "import sys\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "if IN_COLAB:\n",
    "    %pip install -q matplotlib seaborn scikit-learn scipy tqdm optuna\n",
    "    print(\"Colab dependencies installed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039fee50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T20:15:32.849022Z",
     "iopub.status.busy": "2026-02-12T20:15:32.848661Z",
     "iopub.status.idle": "2026-02-12T20:15:34.656801Z",
     "shell.execute_reply": "2026-02-12T20:15:34.656237Z"
    },
    "papermill": {
     "duration": 1.81442,
     "end_time": "2026-02-12T20:15:34.657387",
     "exception": false,
     "start_time": "2026-02-12T20:15:32.842967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# rye add --git https://github.com/ctgk/PRML.git prml\n",
    "\n",
    "import os\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "# Apply the default theme\n",
    "sns.set_theme()\n",
    "\n",
    "try:\n",
    "    import wandb\n",
    "\n",
    "    _wandb_ok = bool(os.environ.get(\"WANDB_API_KEY\"))\n",
    "except ImportError:\n",
    "    wandb = None\n",
    "    _wandb_ok = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e2789f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T20:15:34.661924Z",
     "iopub.status.busy": "2026-02-12T20:15:34.661613Z",
     "iopub.status.idle": "2026-02-12T20:15:34.685922Z",
     "shell.execute_reply": "2026-02-12T20:15:34.685333Z"
    },
    "papermill": {
     "duration": 0.027602,
     "end_time": "2026-02-12T20:15:34.686850",
     "exception": false,
     "start_time": "2026-02-12T20:15:34.659248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import prml\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from prml.preprocess import GaussianFeature, PolynomialFeature, SigmoidalFeature\n",
    "from prml.linear import (\n",
    "    BayesianRegression,\n",
    "    EmpiricalBayesRegression,\n",
    "    LinearRegression,\n",
    "    RidgeRegression,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c85cd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T20:15:34.690306Z",
     "iopub.status.busy": "2026-02-12T20:15:34.690156Z",
     "iopub.status.idle": "2026-02-12T20:15:34.792370Z",
     "shell.execute_reply": "2026-02-12T20:15:34.791654Z"
    },
    "papermill": {
     "duration": 0.104877,
     "end_time": "2026-02-12T20:15:34.793149",
     "exception": false,
     "start_time": "2026-02-12T20:15:34.688272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def create_toy_data(func, sample_size, std, domain=[0, 1]):\n",
    "    rng = np.random.default_rng()\n",
    "    x = np.linspace(domain[0], domain[1], sample_size)\n",
    "    # x = rng.uniform(0, 1, sample_size)\n",
    "    np.random.shuffle(x)\n",
    "\n",
    "    y = func(x) + rng.normal(scale=std, size=x.shape)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def sinusoidal(x):\n",
    "    return np.sin(2 * np.pi * x)\n",
    "\n",
    "\n",
    "m = 20\n",
    "x, y = create_toy_data(sinusoidal, m, 0.25)\n",
    "\n",
    "# Reshape x to work with sklearn (needed if x is a 1D array)\n",
    "x = x.reshape(-1, 1)\n",
    "\n",
    "# Split dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Print the shapes of the splits\n",
    "print(\"Training set size:\", x_train.shape, y_train.shape)\n",
    "print(\"Test set size:\", x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d8fe86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T20:15:34.798455Z",
     "iopub.status.busy": "2026-02-12T20:15:34.798154Z",
     "iopub.status.idle": "2026-02-12T20:15:34.869081Z",
     "shell.execute_reply": "2026-02-12T20:15:34.868417Z"
    },
    "papermill": {
     "duration": 0.074141,
     "end_time": "2026-02-12T20:15:34.869916",
     "exception": false,
     "start_time": "2026-02-12T20:15:34.795775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10, 8])\n",
    "plt.scatter(\n",
    "    x_train, y_train, facecolor=\"none\", edgecolor=\"b\", s=50, label=\"training data\"\n",
    ")\n",
    "plt.scatter(x_test, y_test, facecolor=\"none\", edgecolor=\"r\", label=\"test data\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330dd536",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T20:15:34.874763Z",
     "iopub.status.busy": "2026-02-12T20:15:34.874626Z",
     "iopub.status.idle": "2026-02-12T20:15:35.042665Z",
     "shell.execute_reply": "2026-02-12T20:15:35.042192Z"
    },
    "papermill": {
     "duration": 0.171206,
     "end_time": "2026-02-12T20:15:35.043144",
     "exception": false,
     "start_time": "2026-02-12T20:15:34.871938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "M = 9\n",
    "\n",
    "feature = PolynomialFeature(M)\n",
    "\n",
    "X_train = feature.transform(x_train)\n",
    "X_test = feature.transform(x_test)\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "plt.figure(figsize=[10, 8])\n",
    "plt.plot(model.w)\n",
    "plt.xlabel(\"index of $w$\")\n",
    "plt.ylabel(\"$w$\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=[10, 8])\n",
    "\n",
    "# training data\n",
    "plt.scatter(\n",
    "    x_train, y_train, facecolor=\"none\", edgecolor=\"b\", s=50, label=\"training data\"\n",
    ")\n",
    "# test data\n",
    "plt.scatter(x_test, y_test, facecolor=\"none\", edgecolor=\"r\", s=50, label=\"test data\")\n",
    "\n",
    "# M=9 polynomial regression hypothesis\n",
    "x_range = np.linspace(X_train.min(), X_train.max(), 100).reshape(-1, 1)\n",
    "X_range = feature.transform(x_range)\n",
    "y_hat_range, y_hat_range_std = model.predict(X_range, return_std=True)\n",
    "\n",
    "plt.plot(x_range, y_hat_range, label=\"Least Squares Prediction\")\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$y$ or $\\hat{y}$\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91770a2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T20:15:35.049885Z",
     "iopub.status.busy": "2026-02-12T20:15:35.049719Z",
     "iopub.status.idle": "2026-02-12T20:15:35.069530Z",
     "shell.execute_reply": "2026-02-12T20:15:35.067989Z"
    },
    "papermill": {
     "duration": 0.024538,
     "end_time": "2026-02-12T20:15:35.070592",
     "exception": false,
     "start_time": "2026-02-12T20:15:35.046054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import test\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# SGD Loop with polynomial features and mini-batch support\n",
    "def sgd_loop(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    w,\n",
    "    learning_rate,\n",
    "    epochs,\n",
    "    lambda_reg,\n",
    "    n_samples,\n",
    "    batch_size=1,\n",
    "    log_wandb=False,\n",
    "):\n",
    "    # Arrays to store loss values for visualization\n",
    "    losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    # SGD Loop\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(0, n_samples, batch_size):  # Iterate in mini-batches\n",
    "            # Select a mini-batch of `batch_size`\n",
    "            batch_indices = np.random.choice(n_samples, batch_size, replace=False)\n",
    "            xi = X_train[batch_indices]\n",
    "            yi = y_train[batch_indices]\n",
    "\n",
    "            # Prediction\n",
    "            y_pred = np.dot(xi, w)\n",
    "\n",
    "            # Compute error\n",
    "            error = y_pred - yi\n",
    "\n",
    "            # Compute gradients (Mean of batch gradients)\n",
    "            dw = (2 / batch_size) * (xi.T @ error).flatten() + 2 * lambda_reg * w\n",
    "\n",
    "            # Update weights\n",
    "            w -= learning_rate * dw\n",
    "\n",
    "        # Compute training loss\n",
    "        y_hat_train = X_train @ w\n",
    "        loss = np.mean((y_hat_train - y_train) ** 2) + lambda_reg * np.sum(w**2)\n",
    "        losses.append(loss)\n",
    "\n",
    "        # Compute test loss\n",
    "        y_hat_test = X_test @ w\n",
    "        test_loss = np.mean((y_hat_test - y_test) ** 2) + lambda_reg * np.sum(w**2)\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "        # Log to W&B\n",
    "        if log_wandb and _wandb_ok and wandb is not None:\n",
    "            wandb.log({\"train_loss\": loss, \"test_loss\": test_loss, \"epoch\": epoch})\n",
    "\n",
    "    # Plot loss vs epochs\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(epochs), losses, label=\"Training Loss\", color=\"blue\")\n",
    "    plt.plot(range(epochs), test_losses, label=\"Test Loss\", color=\"red\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training & Test Loss vs Epochs\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Start of plotting regression curve\n",
    "    plt.subplot(1, 2, 2)\n",
    "    x_range = np.linspace(X_train.min(), X_train.max(), 100).reshape(-1, 1)\n",
    "\n",
    "    # computation\n",
    "    hypothesis = np.zeros_like(x_range)\n",
    "    for i in range(len(w)):\n",
    "        hypothesis += w[i] * (x_range**i)  # Add each term: w_i * x^i\n",
    "\n",
    "    # Plot training and testing data points\n",
    "    plt.scatter(x_train, y_train, color=\"blue\", label=\"Training Data\")\n",
    "    plt.scatter(x_test, y_test, color=\"red\", label=\"Test Data\")\n",
    "\n",
    "    # plot our regression curve\n",
    "    plt.plot(x_range, hypothesis, color=\"green\", label=\"Regularized Hypothesis\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.title(\"Regularized 9-degree Polynomial Regression Function\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    min_loss = min(losses)\n",
    "    min_index = losses.index(min_loss)\n",
    "    min_test_loss = min(test_losses)\n",
    "    min_test_index = test_losses.index(min_test_loss)\n",
    "\n",
    "    # Print final parameters\n",
    "    print(\"Final weights:\", w.flatten())\n",
    "    print(f\"Smallest Loss: {min_loss} loss at index {min_index}\")\n",
    "    print(f\"Smallest Test Loss: {min_test_loss} loss at index {min_test_index}\")\n",
    "\n",
    "    return min(test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566d0f2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T20:15:35.080952Z",
     "iopub.status.busy": "2026-02-12T20:15:35.080613Z",
     "iopub.status.idle": "2026-02-12T20:15:38.854066Z",
     "shell.execute_reply": "2026-02-12T20:15:38.852255Z"
    },
    "papermill": {
     "duration": 3.780175,
     "end_time": "2026-02-12T20:15:38.855233",
     "exception": false,
     "start_time": "2026-02-12T20:15:35.075058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_features = X_train.shape[1]  # Number of polynomial features\n",
    "\n",
    "# Replace this vector with the optimal trial vector\n",
    "w = np.array(\n",
    "    [\n",
    "        0.3821733,\n",
    "        0.3096256,\n",
    "        -1.87535451,\n",
    "        -0.41147161,\n",
    "        0.48204058,\n",
    "        -0.47616227,\n",
    "        -0.91596271,\n",
    "        0.33230879,\n",
    "        0.92623104,\n",
    "        1.34749729,\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Init W&B run for single SGD\n",
    "_wb_run = None\n",
    "if _wandb_ok and wandb is not None:\n",
    "    try:\n",
    "        _wb_run = wandb.init(\n",
    "            settings=wandb.Settings(init_timeout=120),\n",
    "            project=\"eng-ai-agents\",\n",
    "            entity=\"pantelis\",\n",
    "            id=\"train-sgd-sinusoidal-single\",\n",
    "            resume=\"allow\",\n",
    "            name=\"sgd-sinusoidal-single\",\n",
    "            group=\"regression\",\n",
    "            tags=[\"regression\"],\n",
    "            job_type=\"training\",\n",
    "            config={\n",
    "                \"learning_rate\": 0.01,\n",
    "                \"epochs\": 10000,\n",
    "                \"lambda_reg\": 0.02,\n",
    "                \"batch_size\": 5,\n",
    "            },\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"W&B init failed (non-fatal): {e}\")\n",
    "        _wb_run = None\n",
    "\n",
    "try:\n",
    "    test_loss = sgd_loop(\n",
    "        X_train=X_train,\n",
    "        y_train=y_train,\n",
    "        X_test=X_test,\n",
    "        y_test=y_test,\n",
    "        w=w,\n",
    "        learning_rate=0.01,\n",
    "        epochs=10000,\n",
    "        lambda_reg=0.02,\n",
    "        n_samples=len(y_train),\n",
    "        batch_size=5,\n",
    "        log_wandb=True,\n",
    "    )\n",
    "\n",
    "    if _wb_run is not None:\n",
    "        _wb_run.summary[\"final_test_loss\"] = test_loss\n",
    "finally:\n",
    "    if _wb_run is not None:\n",
    "        _wb_run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b793e1a",
   "metadata": {
    "papermill": {
     "duration": 0.004861,
     "end_time": "2026-02-12T20:15:38.868264",
     "exception": false,
     "start_time": "2026-02-12T20:15:38.863403",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e47a5ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T20:15:38.877864Z",
     "iopub.status.busy": "2026-02-12T20:15:38.877687Z",
     "iopub.status.idle": "2026-02-12T20:15:38.910801Z",
     "shell.execute_reply": "2026-02-12T20:15:38.909889Z"
    },
    "papermill": {
     "duration": 0.039298,
     "end_time": "2026-02-12T20:15:38.911624",
     "exception": false,
     "start_time": "2026-02-12T20:15:38.872326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # Sample lambda_reg from Optuna (log-uniform for better scaling)\n",
    "    lambda_reg = trial.suggest_loguniform(\n",
    "        \"lambda_reg\", 1e-4, 1.0\n",
    "    )  # Define the search space\n",
    "\n",
    "    # batch_size = trial.suggest_uniform(\n",
    "    #     \"batch_size\", 1, 10\n",
    "    # )  # Define the search space\n",
    "\n",
    "    # Initialize weights\n",
    "    w = np.random.randn(10)\n",
    "\n",
    "    # fix batch size to the size of the training set\n",
    "    batch_size = len(y_train)\n",
    "\n",
    "    # Run SGD\n",
    "    min_test_loss = sgd_loop(\n",
    "        X_train=X_train,\n",
    "        y_train=y_train,\n",
    "        X_test=X_test,\n",
    "        y_test=y_test,\n",
    "        w=w,\n",
    "        learning_rate=0.01,\n",
    "        epochs=10000,\n",
    "        lambda_reg=lambda_reg,\n",
    "        n_samples=len(y_train),\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    return min_test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf00a49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T20:15:38.922188Z",
     "iopub.status.busy": "2026-02-12T20:15:38.921916Z",
     "iopub.status.idle": "2026-02-12T20:16:08.290292Z",
     "shell.execute_reply": "2026-02-12T20:16:08.289547Z"
    },
    "papermill": {
     "duration": 29.374784,
     "end_time": "2026-02-12T20:16:08.290854",
     "exception": false,
     "start_time": "2026-02-12T20:15:38.916070",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Init W&B run for Optuna sweep\n",
    "_wb_run = None\n",
    "if _wandb_ok and wandb is not None:\n",
    "    try:\n",
    "        _wb_run = wandb.init(\n",
    "            settings=wandb.Settings(init_timeout=120),\n",
    "            project=\"eng-ai-agents\",\n",
    "            entity=\"pantelis\",\n",
    "            id=\"train-sgd-sinusoidal-optuna\",\n",
    "            resume=\"allow\",\n",
    "            name=\"sgd-sinusoidal-optuna\",\n",
    "            group=\"regression\",\n",
    "            tags=[\"regression\", \"optuna\"],\n",
    "            job_type=\"training\",\n",
    "            config={\"n_trials\": 50, \"epochs\": 10000},\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"W&B init failed (non-fatal): {e}\")\n",
    "        _wb_run = None\n",
    "\n",
    "try:\n",
    "    # Set direction to \"minimize\" as we want to minimize the objective\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "\n",
    "    n_trials = 50\n",
    "\n",
    "    study.optimize(objective, n_trials=50)  # Run the optimization for 100 trials\n",
    "\n",
    "    # Best lambda_reg\n",
    "    best_lambda_reg = study.best_params[\"lambda_reg\"]\n",
    "    print(f\"Best lambda_reg: {best_lambda_reg}\")\n",
    "    print(f\"Best test loss: {study.best_value}\")\n",
    "\n",
    "    # Best Batch size\n",
    "    best_lambda_reg = study.best_params[\"lambda_reg\"]\n",
    "    print(f\"Best lambda_reg: {best_lambda_reg}\")\n",
    "    print(f\"Best test loss: {study.best_value}\")\n",
    "\n",
    "    # Log Optuna results to W&B\n",
    "    if _wb_run is not None:\n",
    "        _wb_run.summary[\"best_lambda_reg\"] = best_lambda_reg\n",
    "        _wb_run.summary[\"best_test_loss\"] = study.best_value\n",
    "\n",
    "    # Plot optimization history\n",
    "    fig = optuna.visualization.matplotlib.plot_optimization_history(study)\n",
    "    plt.show()\n",
    "\n",
    "    # Upload Optuna plot to W&B\n",
    "    if _wb_run is not None:\n",
    "        _wb_run.log({\"optuna_history\": wandb.Image(plt.gcf())})\n",
    "finally:\n",
    "    if _wb_run is not None:\n",
    "        _wb_run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 36.952722,
   "end_time": "2026-02-12T20:16:09.068945",
   "environment_variables": {},
   "exception": null,
   "input_path": "notebooks/regression/linear-regression/sgd_sinusoidal_dataset.ipynb",
   "output_path": "notebooks/regression/linear-regression/sgd_sinusoidal_dataset-executed.ipynb",
   "parameters": {},
   "start_time": "2026-02-12T20:15:32.116223",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
