{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backbone: ResNet50 + Feature Pyramid Network\n",
    "\n",
    "*Notebook 2 of 6 in the Faster RCNN from-scratch series*\n",
    "\n",
    "We build the feature extractor from scratch: ResNet50 bottleneck blocks,\n",
    "followed by an FPN that produces P2–P5 feature maps at strides 4, 8, 16, 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    \"\"\"ResNet bottleneck block: 1x1 -> 3x3 -> 1x1 with optional downsample.\"\"\"\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_channels: int, mid_channels: int, stride: int = 1,\n",
    "                 downsample: nn.Module = None):\n",
    "        super().__init__()\n",
    "        out_channels = mid_channels * self.expansion\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, mid_channels, 1, bias=False)\n",
    "        self.bn1   = nn.BatchNorm2d(mid_channels)\n",
    "        self.conv2 = nn.Conv2d(mid_channels, mid_channels, 3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2   = nn.BatchNorm2d(mid_channels)\n",
    "        self.conv3 = nn.Conv2d(mid_channels, out_channels, 1, bias=False)\n",
    "        self.bn3   = nn.BatchNorm2d(out_channels)\n",
    "        self.relu  = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        identity = x\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        if self.downsample:\n",
    "            identity = self.downsample(x)\n",
    "        return self.relu(out + identity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50(nn.Module):\n",
    "    \"\"\"ResNet50 backbone returning C2, C3, C4, C5 feature maps.\n",
    "\n",
    "    C2: stride 4,  256 channels\n",
    "    C3: stride 8,  512 channels\n",
    "    C4: stride 16, 1024 channels\n",
    "    C5: stride 32, 2048 channels\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Stem\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(3, stride=2, padding=1),\n",
    "        )\n",
    "        # Layers\n",
    "        self.layer1 = self._make_layer(64,  64,  blocks=3, stride=1)  # C2\n",
    "        self.layer2 = self._make_layer(256, 128, blocks=4, stride=2)  # C3\n",
    "        self.layer3 = self._make_layer(512, 256, blocks=6, stride=2)  # C4\n",
    "        self.layer4 = self._make_layer(1024,512, blocks=3, stride=2)  # C5\n",
    "\n",
    "    def _make_layer(self, in_ch: int, mid_ch: int, blocks: int, stride: int):\n",
    "        out_ch = mid_ch * Bottleneck.expansion\n",
    "        downsample = None\n",
    "        if stride != 1 or in_ch != out_ch:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_ch, out_ch, 1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_ch),\n",
    "            )\n",
    "        layers = [Bottleneck(in_ch, mid_ch, stride, downsample)]\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(Bottleneck(out_ch, mid_ch))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x  = self.stem(x)\n",
    "        c2 = self.layer1(x)\n",
    "        c3 = self.layer2(c2)\n",
    "        c4 = self.layer3(c3)\n",
    "        c5 = self.layer4(c4)\n",
    "        return c2, c3, c4, c5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = ResNet50()\n",
    "x = torch.randn(1, 3, 800, 800)\n",
    "c2, c3, c4, c5 = backbone(x)\n",
    "for name, feat in zip(['C2','C3','C4','C5'], [c2, c3, c4, c5]):\n",
    "    print(f\"{name}: {feat.shape}\")\n",
    "# Expected:\n",
    "# C2: torch.Size([1, 256, 200, 200])\n",
    "# C3: torch.Size([1, 512, 100, 100])\n",
    "# C4: torch.Size([1, 1024, 50, 50])\n",
    "# C5: torch.Size([1, 2048, 25, 25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FPN(nn.Module):\n",
    "    \"\"\"Feature Pyramid Network.\n",
    "\n",
    "    Takes C2-C5 from ResNet50 and produces P2-P5 (+ P6 via pooling).\n",
    "    All pyramid levels have `out_channels` channels (default 256).\n",
    "\n",
    "    P2: stride 4  (200x200 for 800x800 input)\n",
    "    P3: stride 8  (100x100)\n",
    "    P4: stride 16 (50x50)\n",
    "    P5: stride 32 (25x25)\n",
    "    P6: stride 64 (13x13) — only used for large-anchor RPN level\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels: List[int] = [256, 512, 1024, 2048],\n",
    "                 out_channels: int = 256):\n",
    "        super().__init__()\n",
    "        # Lateral 1x1 convs\n",
    "        self.lat2 = nn.Conv2d(in_channels[0], out_channels, 1)\n",
    "        self.lat3 = nn.Conv2d(in_channels[1], out_channels, 1)\n",
    "        self.lat4 = nn.Conv2d(in_channels[2], out_channels, 1)\n",
    "        self.lat5 = nn.Conv2d(in_channels[3], out_channels, 1)\n",
    "        # Output 3x3 convs\n",
    "        self.out2 = nn.Conv2d(out_channels, out_channels, 3, padding=1)\n",
    "        self.out3 = nn.Conv2d(out_channels, out_channels, 3, padding=1)\n",
    "        self.out4 = nn.Conv2d(out_channels, out_channels, 3, padding=1)\n",
    "        self.out5 = nn.Conv2d(out_channels, out_channels, 3, padding=1)\n",
    "\n",
    "    def forward(self, c2, c3, c4, c5):\n",
    "        # Lateral connections\n",
    "        l5 = self.lat5(c5)\n",
    "        l4 = self.lat4(c4) + F.interpolate(l5, size=c4.shape[-2:], mode='nearest')\n",
    "        l3 = self.lat3(c3) + F.interpolate(l4, size=c3.shape[-2:], mode='nearest')\n",
    "        l2 = self.lat2(c2) + F.interpolate(l3, size=c2.shape[-2:], mode='nearest')\n",
    "\n",
    "        p2 = self.out2(l2)\n",
    "        p3 = self.out3(l3)\n",
    "        p4 = self.out4(l4)\n",
    "        p5 = self.out5(l5)\n",
    "        p6 = F.max_pool2d(p5, kernel_size=1, stride=2, padding=0)\n",
    "\n",
    "        return p2, p3, p4, p5, p6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpn = FPN()\n",
    "p2, p3, p4, p5, p6 = fpn(c2, c3, c4, c5)\n",
    "for name, p in zip(['P2','P3','P4','P5','P6'], [p2, p3, p4, p5, p6]):\n",
    "    print(f\"{name}: {p.shape}\")\n",
    "# Expected:\n",
    "# P2: torch.Size([1, 256, 200, 200])\n",
    "# P3: torch.Size([1, 256, 100, 100])\n",
    "# P4: torch.Size([1, 256, 50, 50])\n",
    "# P5: torch.Size([1, 256, 25, 25])\n",
    "# P6: torch.Size([1, 256, 13, 13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load one real image and pass through backbone + FPN\n",
    "# (reuse COCODataset from notebook 01 or load a single image)\n",
    "img = torch.randn(1, 3, 800, 800)  # replace with real image tensor\n",
    "c2, c3, c4, c5 = backbone(img)\n",
    "p2, p3, p4, p5, p6 = fpn(c2, c3, c4, c5)\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
    "for ax, (name, feat) in zip(axes, [('P2',p2),('P3',p3),('P4',p4),('P5',p5),('P6',p6)]):\n",
    "    fmap = feat[0].mean(dim=0).detach().cpu().numpy()  # mean over channels\n",
    "    ax.imshow(fmap, cmap='viridis')\n",
    "    ax.set_title(f\"{name}\\n{feat.shape[-2]}x{feat.shape[-1]}\")\n",
    "    ax.axis('off')\n",
    "plt.suptitle(\"FPN Feature Maps (mean activation)\", fontsize=13)\n",
    "plt.savefig(\"images/fpn_features.png\", dpi=100, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 4, figsize=(16, 3))\n",
    "for ax, (name, feat) in zip(axes, [('P2',p2),('P3',p3),('P4',p4),('P5',p5)]):\n",
    "    vals = feat[0].detach().cpu().numpy().flatten()\n",
    "    ax.hist(vals, bins=50, color='steelblue', alpha=0.7)\n",
    "    ax.set_title(f\"{name} activations\")\n",
    "    ax.set_xlabel(\"Value\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"images/activation_histograms.png\", dpi=100, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = sum(p.numel() for p in backbone.parameters()) + \\\n",
    "        sum(p.numel() for p in fpn.parameters())\n",
    "print(f\"Total backbone+FPN parameters: {total:,}\")\n",
    "# Expected: ~25M backbone + ~1.5M FPN ~= 26.5M"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
